{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HYAhlNXw8ei0"
   },
   "source": [
    "#CSE5DL Assignment\n",
    "\n",
    "### Assignment due date: Friday 27/5/2022\n",
    "\n",
    "Penalties are applied to late assignments (accepted up to 5 business days after the due date only). Five percent is deducted per business day late. A mark of zero will be assigned to assignments submitted more than 5 days late. \n",
    "\n",
    "<font color='red'> This is an individual assignment. You are not permitted to work as a part of a group when writing this assignment. </font>\n",
    "\n",
    "### Assignment submission\n",
    "\n",
    "Please zip all `*.ipynb`, `*.py`, `*.docx` and `*.xlsx` files into a single zip file and submit the zipped file via the link provided on LMS. \n",
    "\n",
    "### Copying, Plagiarism\n",
    "Plagiarism is the submission of somebody elseâ€™s work in a manner that gives the impression that the work is your own. For individual assignments, plagiarism includes the case where two or more students work collaboratively on the assignment.  The Department of Computer Science and Information Technology treats plagiarism very seriously.  When it is detected, penalties are strictly imposed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9yQ1TwYgWS0z"
   },
   "source": [
    "\n",
    "# Introduction\n",
    "\n",
    "**DESCRIPTION:** In this assignment we have provided you with skeleton code. We have an image dataset and a text dataset, and you must train deep learning models for them. With the exception of Task 2b, all of the code required has already been shown to you in the labs.\n",
    "\n",
    "In this assignment you will be required to write code and write short answer responses to questions in a structured report. You have been provided with a template Word document of this report in which you simply have to fill in the blanks (1-3 sentences is expected).\n",
    "\n",
    "Throughout this assignment, there are a few challenge questions worth bonus marks. Task 1 is worth 66 marks and Task 2 is worth 32 marks, totalling 98 marks possible before challenge questions. You can receive up to 10 marks from at most 3 challenge questions, so the maximum number of marks you can get is 108. However if you get over 100 marks the actual mark you will receive is 100% for the assignment assessment component of your grades.  Unless otherwise stated all marks quoted do not include challenge questions.\n",
    "\n",
    "There are 71 marks associated with code and 27 marks associated with the report.\n",
    "\n",
    "**INSTRUCTIONS:**\n",
    "\n",
    "1.   Copy the skeleton files to your Google Drive.\n",
    "2.   Edit `SKELETON_DIR` in the first cell to point to the skeleton files you uploaded in step 1. The provided code assumes you have uploaded them to \"Uni/CSE5DL/Assignment\" in your Google Drive.\n",
    "3.   Run the following two cells\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DI_h0wYR8WwZ"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Set the working directory for the assignment\n",
    "import os\n",
    "SKELETON_DIR = '/content/drive/MyDrive/Uni/CSE5DL/Assignment'\n",
    "os.chdir(SKELETON_DIR)\n",
    "! mkdir -p \"$SKELETON_DIR/saved_models\"\n",
    "! mkdir -p \"$SKELETON_DIR/logs\"\n",
    "\n",
    "# Set up auto-reloading modules from the working directory\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Install extra dependencies\n",
    "!pip install -q transformers==3.4.0\n",
    "!pip install -q wandb==0.10.8\n",
    "!pip install -q torchmetrics==0.7.2\n",
    "\n",
    "# Set the default figure size\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.dpi'] = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "McyD2WEJJDz6"
   },
   "outputs": [],
   "source": [
    "%%shell\n",
    "DATA_URL='https://cloudstor.aarnet.edu.au/plus/s/00M4iLi0DYJzDsn/download'\n",
    "\n",
    "pushd /content\n",
    "wget $DATA_URL -O data.zip\n",
    "unzip -q data.zip\n",
    "popd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0UMZDfCl9uzf"
   },
   "source": [
    "# Task 1 - Image Classification\n",
    "\n",
    "**MARKS**: 66\n",
    "\n",
    "In this first task, you will create a deep learning model to classify images of skin lesions into one of seven classes: \n",
    "\n",
    "1.   \"MEL\" = Melanoma\n",
    "2.   \"NV\" = Melanocytic nevus\n",
    "3.   \"BCC\" = Basal cell carcinoma\n",
    "4.   \"AKIEC\" = Actinic keratosis\n",
    "5.   \"BKL\" = Benign keratosis\n",
    "6.   \"DF\" = Dermatofibroma\n",
    "7.   \"VASC\" = Vascular lesion\n",
    "\n",
    "The data for this task is a subset of: https://challenge2018.isic-archive.com/task3/\n",
    "\n",
    "The data for this task is inside the `/content/data/img` folder. It contains ~3,800 images named like `ISIC_000000.jpg` and the following label files:\n",
    "\n",
    "*   `/content/data/img/train.csv`\n",
    "*   `/content/data/img/val.csv`\n",
    "*   `/content/data/img/train_small.csv`\n",
    "*   `/content/data/img/val_small.csv`\n",
    "\n",
    "The `small` versions are the first 200 lines of each partition and are included for debugging purposes. To save time, ensure your code runs on the `small` versions first.\n",
    "\n",
    "**NOTE**: To explore the labels, you can click the above hyperlinks to open the relevant csv file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VXe_oJsh2v0R"
   },
   "source": [
    "## Task 1a. Explore the training set\n",
    "\n",
    "**MARKS**: 5 (Code 3, Reports 2)\n",
    "\n",
    "**INSTRUCTIONS**: Check for data issues, as we have done in the labs. Check the class distribution and at least 1 other potential data issue. Hint: Look in `explore.py` for a function that can plot the class distribution.\n",
    "\n",
    "**REPORT**: What did you check for? What data issues are present in this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tvZcHWR_nrN_"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "IMG_CLASS_NAMES = [\"MEL\", \"NV\", \"BCC\", \"AKIEC\", \"BKL\", \"DF\", \"VASC\"]\n",
    "\n",
    "train_df = pd.read_csv('/content/data/img/train.csv')\n",
    "val_df = pd.read_csv('/content/data/img/val.csv')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dpqxCqPth8va"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "# Change the filename to view other examples from the dataset \n",
    "display(Image.open('/content/data/img/ISIC_0024306.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J6nJ9TKkDM_E"
   },
   "outputs": [],
   "source": [
    "import explore\n",
    "\n",
    "# TODO - Check for data issues\n",
    "# Hint: You can convert from one-hot to integers with argmax\n",
    "#       This way you can convert 1, 0, 0, 0, 0, 0, 0  to class 0 \n",
    "#                                0, 1, 0, 0, 0, 0, 0  to class 1\n",
    "#                                0, 0, 1, 0, 0, 0, 0  to class 2\n",
    "# so it should be something like the following: \n",
    "# train_labels = train_df.values[....].argmax(....)\n",
    "# val_labels = val_df.values[....].argmax(....)\n",
    "#     - you need to fill in the ... parts with the correct values.\n",
    "# You should then print output the contents of train_labels to see if \n",
    "# it matches the contents of train.csv\n",
    "#\n",
    "# Next you can plot the class distributions like the following:\n",
    "# explore.plot_label_distribution(....)\n",
    "#    - do the above for both the train and val labels.\n",
    "#\n",
    "# Following this look for other potential problems with the data\n",
    "#   You can look at lab 2a to see what was checked there.\n",
    "#   You may also think of any other potential problems with the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EzxriiNQ22CG"
   },
   "source": [
    "## Task 1b. Implement Training loop\n",
    "\n",
    "**MARKS**: 17 (Code 15, Reports 2)\n",
    "\n",
    "**INSTRUCTIONS**:\n",
    "\n",
    "*   Implement LesionDataset in `datasets.py`. Use the cell below to test your implementation. \n",
    "*   Implement the incomplete functions in `train.py` marked as \"Task 1b\"\n",
    "*   Go to the [Model Training Cell](#task-1-model-training) at the end of Task 1 and fill in the required code for \"Task 1b\".\n",
    "\n",
    "**REPORT**: Why should you *not use* `random_split` in your code here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-uZTyqK9XvsJ"
   },
   "outputs": [],
   "source": [
    "import datasets\n",
    "\n",
    "ds = datasets.LesionDataset('/content/data/img',\n",
    "                            '/content/data/img/train.csv')\n",
    "input, label = ds[0]\n",
    "print(input)\n",
    "print(label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dg_P1_Pd26Bm"
   },
   "source": [
    "## Task 1c. Implement a baseline convolutional neural networks\n",
    "\n",
    "**MARKS**: 17 (Code 12, Reports 5)\n",
    "\n",
    "You will implement a baseline convolutional neural network which you can compare results to. This allows you to evaluate any improvements made by hyperparameter tuning or transfer learning.\n",
    "\n",
    "**INSTRUCTIONS**:\n",
    "\n",
    "*   Implement a `SimpleBNConv` in `models.py` with:\n",
    "    *   5 `nn.Conv2d` layers, with 8, 16, 32, 64, 128 output channels respectively, with the following between each convolution layer:\n",
    "        *   `nn.ReLU()` for the activation function, and\n",
    "        *   `nn.BatchNorm2d`, and\n",
    "        *   finally a `nn.MaxPool2d` to downsample by a factor of 2.\n",
    "*   Use a normalised confusion matrix on the model's validation predictions in `train.py`.\n",
    "*  Go to the [Model Training Cell](#task-1-model-training) at the end of Task 1 and fill in the required code to train the model.\n",
    "\n",
    "Training should take about 1 minute/epoch. Validation accuracy should be 60-70%, but UAR should be around 20-40%.\n",
    "\n",
    "**REPORT**: As training sets get larger, the length of time per epoch also gets larger. Some datasets take over an hour per epoch. This makes it impractical to debug typos in your code since it can take hours after starting for the program to reach new code. Name two ways to significantly reduce how long each epoch takes - for debugging purposes - while still using real data and using the real training code.\n",
    "\n",
    "**REPORT**: Show the confusion matrix and plots of the validation accuracy and UAR in your report, and explain what is going wrong. \n",
    "(Right-click a plot and select \"save image as...\" to save the image to your computer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bnlbHlO953Dw"
   },
   "source": [
    "## Task 1d. Account for data issues\n",
    "\n",
    "**MARKS**: 6 (Code 3, Reports 3)\n",
    "\n",
    "**INSTRUCTIONS**: Account for the data issues in Task 1a and retrain your model.\n",
    "\n",
    "**REPORT**: How did you account for the data issues? Was it effective? How can you tell? Show another confusion matrix.\n",
    "\n",
    "**IMPORTANT NOTE**: One of the techniques from the lab will cause a warning in the metric calculation on `train_small.csv`, but will work fine on `train.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z4bd8vMQ3C6b"
   },
   "source": [
    "## Task 1e. Data Augmentation\n",
    "\n",
    "**MARKS**: 6 (Code 3, Reports 3)\n",
    "\n",
    "**INSTRUCTIONS**: \n",
    "\n",
    "*   Add an `augment` flag to LesionDataset which specifies whether any augmentation is done to the images. Ensure it is set to `True` *only* for the training dataset.\n",
    "*   Use random horizontal flips\n",
    "*   Use at least 2 other different non-deterministic augmentations\n",
    "\n",
    "**REPORT:** Are random vertical flips appropriate for this dataset? Why?\n",
    "\n",
    "Using data augmentation does not guarantee improved model performance. Data augmentation can hurt test performance by making the model train on unrealistic images.\n",
    "\n",
    "**REPORT**: What effect did Data Augmentation have on performance? Show a screenshot of the relevant graphs from Weights & Biases for evidence.\n",
    "\n",
    "**CHALLENGE**: (3 marks) Apply 5 crop augmentation with crop size 200x300. Make a distinct model which uses 5 crops at once to give a single answer. Include in your report how you did this and report the effect on performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3DkP5Mg48Gm1"
   },
   "source": [
    "## Task 1f. Chase improved performance\n",
    "\n",
    "**MARKS**: 15 (Code and reports not separable for this task)\n",
    "\n",
    "**INSTRUCTIONS**: \n",
    "*   Create a model from a pre-trained model from the torchvision model zoo. We recommend Resnet18, but you may use any model you like. You may freeze the weights of all layers except the last, or fine-tune all the weights. https://cloudstor.aarnet.edu.au/plus/s/TsYJXyJWch0h7TD\n",
    "*   Create your own models, modifying the model architecture, try different losses, learning rates. Change anything you like except the evaluation metrics in search of a better model.\n",
    "\n",
    "Train at least 10 different models, each with a different combination.\n",
    "\n",
    "**REPORT**: Create a table in an excel spreadsheet that is similar to that used in Lab 3 to record your results. Make sure it includes every parameter of variation between your combinations as a separate column. Include notes about what you were thinking/hoping for each combination as a number column in the spreadsheet.\n",
    "\n",
    "In addition to the excel spreadsheet generate a report using Weights and Biases of the models you trained and the performance curves. Save the report as a pdf and include this in your submission. Please see this link on how to generate reports with Weights and Biases. https://docs.wandb.ai/guides/reports\n",
    "\n",
    "Play around with Weights and Biases to see what cool features you can dig out and use to better visualize the training results and use that to improve the information shared via the report. \n",
    "\n",
    "Write a discussion about the key findings from the experimental results.\n",
    "\n",
    "**CHALLENGE REPORT**: (3 marks) Assuming you use the full dataset in a single epoch, if you halve the size of the batch size, what happens to the number of times that you update the weights per epoch? With reference to the gradients, under what circumstances is this good?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RxhIzDQjt4mu"
   },
   "source": [
    "<a name=\"task-1-model-training\"></a>\n",
    "## Model Training Cell\n",
    "\n",
    "Note we will be using Weights and Biases to keep track of our experimental runs and evaluation metrics. This is similar to lab 6. Please see lab 6 to learn how to use Weights and Biases. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2tFG3cT2i53Q"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "\n",
    "import datasets\n",
    "import models\n",
    "import train\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "NUM_EPOCHS = 5\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Create datasets/loaders\n",
    "# TODO Task 1b - Create the data loaders from LesionDatasets\n",
    "# TODO Task 1d - Account for data issues, if applicable\n",
    "# train_dataset = ...\n",
    "# val_dataset = ...\n",
    "# train_loader = ...\n",
    "# val_loader = ...\n",
    "\n",
    "\n",
    "# Instantiate model, optimizer and criterion\n",
    "# TODO Task 1c - Make an instance of your model\n",
    "# TODO Task 1d - Account for data issues, if applicable\n",
    "# model = ...\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train model\n",
    "# TODO Task 1c: Set ident_str to a string that identifies this particular\n",
    "#               training run. Note this line in the training code\n",
    "#                     exp_name = f\"{model.__class__.__name__}_{ident_str}\"\n",
    "#               So it means the the model class name is already included in the\n",
    "#               exp_name string. You can consider adding other information \n",
    "#               particular to this training run, e.g. learning rate (lr) used, \n",
    "#               augmentation (aug) used or not, etc.\n",
    "\n",
    "train.train_model(model, train_loader, val_loader, optimizer, criterion,\n",
    "                  IMG_CLASS_NAMES, NUM_EPOCHS, project_name=\"CSE5DL Assignment Task 1\",\n",
    "                  ident_str= \"fill me in here\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nHmk8S-B3PkF"
   },
   "source": [
    "# Task 2 - News article classification\n",
    "\n",
    "**MARKS**: 32\n",
    "\n",
    "You will first create your own model to classify news articles into one of the following classes:\n",
    "\n",
    "*   World\n",
    "*   Sport\n",
    "*   Business\n",
    "*   Sci/Tech\n",
    "\n",
    "You will then compare it to a pre-trained DistilBERT model that has been fine-tuned, similar to Lab 6. Note: using a model pre-trained on a source task for a new target task is called \"transfer learning\" whether you fine-tune it or not.\n",
    "\n",
    "The data for this task is a subset of: https://github.com/mhjabreel/CharCnn_Keras/tree/master/data/ag_news_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DThd7TE73SVK"
   },
   "source": [
    "## Task 2a. Exploring the dataset\n",
    "\n",
    "**MARKS**: 3 (Code 2, Reports 1)\n",
    "\n",
    "**INSTRUCTIONS**: Check for at least 2 data issues.\n",
    "\n",
    "**REPORT**: What did you check for? What data issues exist, if any? Report anything you checked even if it turned out the data did not have that issue. We want to know what you are checking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jJdQupWVOuOw"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "with open('/content/data/txt/classes.txt') as f:\n",
    "    TXT_CLASS_NAMES = [line.rstrip('\\n') for line in f]\n",
    "\n",
    "train_df = pd.read_csv('/content/data/txt/train.csv', header=None)\n",
    "val_df = pd.read_csv('/content/data/txt/val.csv', header=None)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8ULAXaX9F1SJ"
   },
   "outputs": [],
   "source": [
    "import explore\n",
    "# TODO Check for data issues.\n",
    "# Again you should fill in the following:\n",
    "# train_labels = ...\n",
    "# val_labels = ....\n",
    "#   - Note the csv file has class labels start from 1 but\n",
    "#     pytorch expects class labels to start from 0 instead. \n",
    "#\n",
    "# explore.plot_label_distribution(....) for train labels\n",
    "# explore.plot_label_distribution(....) for val labels\n",
    "# \n",
    "# check for other kinds of problems with the data like you did for Task 1a.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AiR4YMsC3WTf"
   },
   "source": [
    "## Task 2b. Clustering and visualising embeddings from a pre-trained model\n",
    "\n",
    "**MARKS**: 14 (Code 11, Reports 3)\n",
    "\n",
    "**INSTRUCTIONS**: \n",
    "\n",
    "*  Implement the `TextDataset` class in the `datasets.py` file. Consider adding a small code block to test your implementation, as provided in task 1b.\n",
    "\n",
    "*   Complete `visualise_embeddings.py` and run it. This will:\n",
    "    *   visualise embeddings of the news articles from a pre-trained `'distilbert-base-uncased'` model (i.e. not yet fine-tuned on the labels) using a combination of PCA and T-SNE. T-SNE is a popular dimensionality reduction method that takes data from a high dimensional space and reduces it to just two dimensions while trying to preserve the right distances between points. T-SNE works best when the input dimensionality is is only moderately high (50 or less dimensions, so we first use PCA to reduce the dimensionality of the embedding to 50 dimensions and then use T-SNE to reduce the embedding from 50 dimensions to 2. The visualization will represent each article by a point with a color corresponding to their true label. Ideally the colors are well separated into separate clusters. If this happens it will be really cool since it means we did not even need to fine-tune the model on our data, it is already able to separate the classes.\n",
    "    *   Next the code will run K-Means clustering on the validation set to group the data into separate clusters. The code will then colour the points based on which cluster they belong to rather than the ground truth label. \n",
    "\n",
    "\n",
    "**REPORT**: By looking at the resulting images, which two classes have the most similar embeddings? How can you tell? Did you expect this, if so, why, if not why not?\n",
    "\n",
    "**CHALLENGE**: (8 marks) Only attempt this after completing the rest of Task 2.\n",
    "\n",
    "*   Modify `visualise_embeddings.py` so that it can load the weights for a fine-tuned DistilBERT model. Then visualize the data points with their corresponding true labels. \n",
    "*   Next instead of using K-Means for the second visualisation, use the model's own predicted labels to colour the points.\n",
    "\n",
    "Present the resulting image in your report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f2yOEBQcF2yO"
   },
   "outputs": [],
   "source": [
    "import visualise_embeddings\n",
    "SENTENCE_LEN = 80\n",
    "visualise_embeddings.mk_plots(SENTENCE_LEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aGx4lFbx3bS5"
   },
   "source": [
    "## Task 2c. Models\n",
    "\n",
    "**MARKS**: 10 (Code 7, Reports 3)\n",
    "\n",
    "**INSTRUCTIONS**:\n",
    "\n",
    "*   Complete `TextMLP` in `models.py`. It should be a simple MLP with 8 Linear layers. It should first embed the inputs into a vocabulary of size 30522. Use an output feature size of 256 in all hidden layers and a feature size of 128 for the embeddings. Flatten the sentence after embedding, but before it goes into any Linear layers. Use batch norm and ReLU. Train for 1000 epochs with learning rate of 0.001 and a batch size of 512.\n",
    "*   Complete `DistilBertForClassification` in `models.py`. This model should replace the last layer with an `nn.Linear` with 4 outputs for classification. Hint: Call `print()` on the DistilBERT model to observe the layers and their names before attempting this. Train for 4 epochs with learning rate of 0.001 and a batch size of 64.\n",
    "\n",
    "Each of these should take around 10 minutes to complete.\n",
    "\n",
    "Go to the [Model Training Cell](#task-2-model-training) at the end of Task 2 and fill in the required code to train the model.\n",
    "\n",
    "**REPORT**: The saved model weights of a fine-tuned DistilBERT model are >200MB, but you only created one small `nn.Linear` layer. Why is the saved model so large? \n",
    "\n",
    "**REPORT**: These models should accept only input with a dtype of `torch.int64`. What do each of these longs (`int64`) represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IRhQjiDtQbFM"
   },
   "source": [
    "## Task 2d. Learning Rate\n",
    "\n",
    "**MARKS**: 5 (Code 0, Reports 5)\n",
    "\n",
    "Fine-tuning `DistilBertForSequenceClassification` with Adam at a learning rate of 0.001 results in very poor accuracy (~26%).\n",
    "\n",
    "**INSTRUCTIONS**: \n",
    "\n",
    "*   Uncomment the lines marked `Task 2d` in `train.py`\n",
    "*   Execute the below cell to begin training and observe the class distribution per batch\n",
    "*   Comment the lines marked `Task 2d` in `train.py` so they no longer interfere with the training.\n",
    "\n",
    "\n",
    "**REPORT**: What is wrong with the class distributions? The learning rate can be changed to fix it. Should you increase or decrease the learning rate? How can you tell?\n",
    "\n",
    "**REPORT**: After fixing the learning rate, comment on the relative train/val performance between these two models. Which model performed better on each partition? Is this expected? If so, why?\n",
    "\n",
    "When you have finished Task 2d. Go back to Task 2b and finish the challenge if you are up to it. You should get a pleasant surprise if you have done everything correctly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jkIB_B2t_yps"
   },
   "source": [
    "<a name=\"task-2-model-training\"></a>\n",
    "## Model Training Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sb3PAZIGF35d"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import datasets\n",
    "import models\n",
    "import train\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "SENTENCE_LEN = 80\n",
    "NUM_EPOCHS = 4\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Create datasets/loaders\n",
    "# TODO: Create the data loaders from TextDatasets\n",
    "# train_dataset = ...\n",
    "# val_dataset = ...\n",
    "# train_loader = ...\n",
    "# val_loader = ...\n",
    "\n",
    "\n",
    "# Instantiate model, optimizer and criterion\n",
    "# TODO: Make an instance of your model\n",
    "# model = models.<**put the name of the model class you created in the model file here**>\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# TODO Change ident_str to something that identifying this experiment e.g. lr0001\n",
    "# Train model. We are using the same train model function we wrote for task 1.\n",
    "train.train_model(model, train_loader, val_loader, optimizer, criterion,\n",
    "                  TXT_CLASS_NAMES, NUM_EPOCHS, project_name = \"CSE5DL Assignment Task 2\",\n",
    "                  ident_str='**fill me in**')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KEJsOR8t3oFA"
   },
   "source": [
    "# Super challenge tasks\n",
    "\n",
    "These challenge tasks are quite difficult and will really test your mastery of PyTorch and `nn.Linear` layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bo9kWUc1ga2_"
   },
   "source": [
    "## Super challenge 1. Manually assigning weights\n",
    "\n",
    "**MARKS**: 5\n",
    "\n",
    "We can manually assign weights to an `nn.Linear` like this:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WNSRGuIFhPD8"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "lin = nn.Linear(10, 20)\n",
    "manual_weights = torch.arange(20*10).reshape(lin.weight.shape)\n",
    "lin.weight.data[:] = manual_weights\n",
    "lin.bias.data[:] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IY8ecPzVhqeL"
   },
   "source": [
    "But this does not calculate anything useful. A Linear layer simply performs a weighted sum (plus bias). We can choose weights/biases to perform known operations.\n",
    "\n",
    "**INSTRUCTIONS**: \n",
    "1.   Given an `nn.Linear(1, 1)` layer, set the weights such that the layer adds 1 to it's input.\n",
    "2.   Given an `nn.Linear(1, 1)` layer, set the weights such that the layer calculates `y = 3x + 2`.\n",
    "3.   Given an `nn.Linear(4, 1)` layer, set the weights such that the layer calculates the average of it's inputs.\n",
    "4.   Given an `nn.Linear(4, 2)` layer, set the weights such that the layer calculates both the average of it's inputs and the sum of the inputs.\n",
    "5.   Given an `nn.Linear(3, 3)` layer, set the weights such that the layer returns the inputs, but in reverse order.\n",
    "6.   Given an `nn.Linear(5, 2)` layer, set the weights such that the layer always returns `(4,2)`\n",
    "\n",
    "\n",
    "Note: We would never use this in a deep learning model; this challenge is to prove that you understand the mathematics and coding mechanics of the `nn.Linear` layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "py6eOCV4hp8z"
   },
   "outputs": [],
   "source": [
    "import sc1\n",
    "sc1.test_1(sc1.modify_lin_1)\n",
    "sc1.test_2(sc1.modify_lin_2)\n",
    "sc1.test_3(sc1.modify_lin_3)\n",
    "sc1.test_4(sc1.modify_lin_4)\n",
    "sc1.test_5(sc1.modify_lin_5)\n",
    "sc1.test_6(sc1.modify_lin_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5zyRfVEhkCvx"
   },
   "source": [
    "## Super challenge 2. Convert to fully convolutional\n",
    "\n",
    "**MARKS**: 5\n",
    "\n",
    "**This question is very difficult to understand, however the solution is very short and powerful**\n",
    "\n",
    "Take an image from the dataset, upsample it to 2x it's size, load a model you trained from Task 1 and try to run it on the upsampled image. It will crash at the `nn.Linear` because the input image size is different to that which it was trained on.\n",
    "\n",
    "A model is \"fully convolutional\" if it uses only locally connected layers: e.g. `nn.Conv2d`, `nn.MaxPool2d`; i.e. no `nn.Linear`. This allows them to operate on any size input image. Where possible, we should use fully convolutional networks to increase portability of our models. But what if we've already created trained a model using a fully connected layer? Are we stuck having to train a new model?\n",
    "\n",
    "In the Overfeat paper (https://arxiv.org/abs/1312.6229) they describe a method to convert a model with a fully connected layer at the end into a fully convolutional model without re-training anything. We will describe the method here. Feel free to try reading the paper but don't be discouraged if it makes no sense; it's a complicated paper with many ideas presented in a less-than-clear way.\n",
    "\n",
    "We will ignore the bias for now. Consider the calculation a `nn.Linear` layer is doing. It's a map from `m` features to `n` features, where each output feature is a linear combination of each of the inputs. Thus there are `m` x `n` weights in a `nn.Linear` layer (not including bias).\n",
    "\n",
    "Now consider a convolution layer with a kernel size the same size as the input image. Let the number of input pixels total `m`, input channels be `1` and the number of output channels be `n`. Then, such a convolution layer is performing the same mapping as the `nn.Linear` layer.\n",
    "\n",
    "So, to convert an `nn.Linear` to an `nn.Conv2d` it is a matter of copying the weights from the former to the latter such that they calculate the same thing. Similarly for the bias.\n",
    "\n",
    "**Instructions**:\n",
    "*   Complete the below code to convert an arbitrary `nn.Linear` to an `nn.Conv2d` which calculates the same thing\n",
    "*   Take an image from the training set:\n",
    "    *   Upsample it to 2x it's size\n",
    "    *   Run the model on it, to get a heatmap per class\n",
    "    *   Visualise those heatmaps\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qKRa4aeX-ao-"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import models\n",
    "\n",
    "\n",
    "NEW_WIDTH = 1200\n",
    "img = Image.open('/content/data/img/ISIC_0024306.jpg')\n",
    "largify = transforms.Resize(NEW_WIDTH)\n",
    "to_tensor = transforms.ToTensor()\n",
    "img_sm = to_tensor(img)[None, :]\n",
    "img_lg = to_tensor(largify(img))[None, :]\n",
    "\n",
    "# TODO - Load your model\n",
    "\n",
    "\n",
    "# Check outputs before modification\n",
    "result1 = model(img_sm)\n",
    "print(torch.flatten(result1).tolist())\n",
    "# This next line will crash because of the linear layer\n",
    "# result2 = model(img_lg)\n",
    "# print(result2)\n",
    "\n",
    "\n",
    "# TODO - \n",
    "# Replace the Linear layer with a Conv Layer that has equivalent weights\n",
    "\n",
    "\n",
    "# Ensure that it still gives the same result\n",
    "result3 = model(img_sm)\n",
    "print(torch.flatten(result3).tolist())\n",
    "result4 = model(img_lg)\n",
    "print(result4.shape)\n",
    "\n",
    "assert torch.allclose(torch.flatten(result1), torch.flatten(result3))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
